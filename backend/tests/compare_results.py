#!/usr/bin/env python3
"""
å¯¹æ¯” Tier6+Model å’Œ DS_TPU çš„è¯„ä¼°ç»“æœ

éªŒè¯ï¼š
1. ç®—å­å»¶è¿Ÿæ˜¯å¦ä¸€è‡´
2. æ¨¡å‹æ€»å»¶è¿Ÿæ˜¯å¦ä¸€è‡´
3. MFUã€ååé‡ç­‰æŒ‡æ ‡æ˜¯å¦ä¸€è‡´
"""

import sys
import json
from pathlib import Path

# æ·»åŠ è·¯å¾„
tier6_backend = Path(__file__).parent.parent
ds_tpu_root = Path("/Users/lixiang/Documents/å·¥ä½œ/code/DS_TPU_1209")

sys.path.insert(0, str(tier6_backend))
sys.path.insert(0, str(ds_tpu_root))


def test_single_operator_comparison():
    """å¯¹æ¯”å•ä¸ªç®—å­çš„è¯„ä¼°ç»“æœ"""
    print("="*80)
    print("å•ä¸ª GEMM ç®—å­å¯¹æ¯”")
    print("="*80)

    # DS_TPU è¯„ä¼°
    from performance.evaluate.compute.matmul.matmul_eval import MatmulEval
    from performance.evaluate.compute.comp_eval_base import TPUArch

    ds_arch = TPUArch(
        tpu_cores=64,
        cube_m=32, cube_n=32, cube_k=32,
        sram_size=8*1024*1024,
        lane_num=32, align_bytes=64,
        macs_per_cycle=32*32, freq=1.2e9,
        dma_bw=273*1e9,
        tpu_gdma_overlap_rate=0.5,
    )
    ds_evaluator = MatmulEval(ds_arch, input_dtype='fp8', output_dtype='bf16')

    # Tier6 è¯„ä¼°
    from llm_simulator.evaluators import get_arch_preset, create_gemm_evaluator

    tier6_arch = get_arch_preset("SG2260E")
    tier6_evaluator = create_gemm_evaluator(
        tier6_arch,
        fast_mode=False,
        enable_partition_search=True
    )

    # æµ‹è¯•ç”¨ä¾‹ï¼ˆç›¸åŒçš„ GEMM å½¢çŠ¶ï¼‰
    test_cases = [
        ("Decode MoE Gate", 1, 384, 7168, 2048),
        ("Decode MLA Q_down", 1, 48, 7168, 1536),
        ("Decode MLA Q_up", 1, 6144, 1536, 192),
    ]

    print("\n" + "-"*80)
    print(f"{'ç®—å­':<25} {'DS_TPUå»¶è¿Ÿ':<15} {'Tier6å»¶è¿Ÿ':<15} {'å·®å¼‚':<15} {'çŠ¶æ€'}")
    print("-"*80)

    all_close = True
    for name, G, M, K, N in test_cases:
        # DS_TPU
        ds_result = ds_evaluator.eval_p(name, G, M, K, N)
        ds_latency = ds_result.elapse if ds_result else 0

        # Tier6
        tier6_result = tier6_evaluator.evaluate(
            G, M, K, N,
            input_dtype='fp8',
            output_dtype='bf16',
            use_multiprocess=True
        )
        tier6_latency = tier6_result.latency_us

        # å¯¹æ¯”
        diff_pct = abs(ds_latency - tier6_latency) / ds_latency * 100 if ds_latency > 0 else 0
        status = "âœ…" if diff_pct < 10 else "âš ï¸" if diff_pct < 30 else "âŒ"

        if diff_pct >= 30:
            all_close = False

        print(f"{name:<25} {ds_latency:>13.2f}Î¼s {tier6_latency:>13.2f}Î¼s {diff_pct:>13.1f}% {status}")

    print("-"*80)

    if all_close:
        print("\nâœ… æ‰€æœ‰ç®—å­å»¶è¿Ÿå·®å¼‚ <30%")
    else:
        print("\nâŒ éƒ¨åˆ†ç®—å­å»¶è¿Ÿå·®å¼‚ >=30%")

    return all_close


def test_model_level_comparison():
    """å¯¹æ¯”å®Œæ•´æ¨¡å‹çš„è¯„ä¼°ç»“æœ"""
    print("\n" + "="*80)
    print("å®Œæ•´æ¨¡å‹è¯„ä¼°å¯¹æ¯” (Decode æ¨¡å¼)")
    print("="*80)

    # DS_TPU è¯„ä¼°
    from model.model_factories import model_factory
    from tpu.tpu_factories import tpu_factory
    from performance.analyzer import PerformanceAnalyzer
    from config.deployment_config import DeploymentConfig
    from config.config_loader import load_model_config
    import time

    model_cfg = load_model_config('deepseek-v3.2')
    deploy_cfg = DeploymentConfig(
        batch_size=1536,
        q_seq_len=1,  # Decode
        kv_seq_len=8192,
        tp=1, dp=32, moe_tp=1, ep=32,
        is_prefill=False,
    )

    print("\nã€DS_TPUã€‘")
    ds_start = time.time()
    model = model_factory.create_model(model_cfg, deploy_cfg.__dict__, 'DeepSeek-V3.2')
    tpu = tpu_factory.create_tpu('v1', {'core': 64})
    analyzer = PerformanceAnalyzer(model, tpu, deploy_cfg, {})
    ds_time = time.time() - ds_start

    ds_perf = analyzer.analysis_summary.get('performance', {})
    ds_latency = ds_perf.get('total_elapse_us', 0) / 1000  # us -> ms
    ds_tps = ds_perf.get('tps', 0)
    ds_mfu = ds_perf.get('mfu', 0) * 100

    print(f"  è¯„ä¼°è€—æ—¶: {ds_time:.2f}s")
    print(f"  æ¨¡æ‹Ÿå»¶è¿Ÿ: {ds_latency:.2f}ms")
    print(f"  ååé‡: {ds_tps:.2f} tokens/s")
    print(f"  MFU: {ds_mfu:.2f}%")

    # Tier6 è¯„ä¼°ï¼ˆåªè¯„ä¼°ç®—å­ï¼Œä¸è¿è¡Œå®Œæ•´æ¨¡æ‹Ÿï¼‰
    print("\nã€Tier6+Model - ç®—å­çº§åˆ«è¯„ä¼°ã€‘")
    from llm_simulator.evaluators import get_arch_preset, create_gemm_evaluator

    tier6_arch = get_arch_preset("SG2260E")
    tier6_gemm = create_gemm_evaluator(tier6_arch, fast_mode=False, enable_partition_search=True)

    # æ‰‹åŠ¨è¯„ä¼°ä¸€ä¸ªä»£è¡¨æ€§å±‚ï¼ˆMoEå±‚ï¼‰
    print("\n  è¯„ä¼°ä»£è¡¨æ€§ MoE å±‚:")

    # MLA Attention éƒ¨åˆ†
    mla_ops = [
        ("Q_down", 1, 48, 7168, 1536),
        ("Q_up", 1, 6144, 1536, 192),
        ("KV_down", 1, 48, 7168, 512),
        ("KV_nope_up", 1, 6144, 512, 128),
        ("KV_v_up", 1, 6144, 512, 128),
        ("O_proj", 1, 48, 16384, 7168),
    ]

    mla_total_latency = 0
    for name, G, M, K, N in mla_ops:
        result = tier6_gemm.evaluate(G, M, K, N, 'fp8', 'bf16', use_multiprocess=True)
        mla_total_latency += result.latency_us
        print(f"    {name}: {result.latency_us:.2f}Î¼s")

    # MoE FFN éƒ¨åˆ†
    moe_ops = [
        ("Routed Gate", 1, 384, 7168, 2048),   # 48*8 experts
        ("Routed Up", 1, 384, 7168, 2048),
        ("Routed Down", 1, 384, 2048, 7168),
        ("Shared Gate", 1, 48, 7168, 2048),
        ("Shared Up", 1, 48, 7168, 2048),
        ("Shared Down", 1, 48, 2048, 7168),
    ]

    moe_total_latency = 0
    for name, G, M, K, N in moe_ops:
        result = tier6_gemm.evaluate(G, M, K, N, 'fp8', 'bf16', use_multiprocess=True)
        moe_total_latency += result.latency_us
        print(f"    {name}: {result.latency_us:.2f}Î¼s")

    # å•å±‚å»¶è¿Ÿ
    layer_latency = (mla_total_latency + moe_total_latency) / 1000  # us -> ms
    print(f"\n  å•å±‚æ€»å»¶è¿Ÿ: {layer_latency:.2f}ms")

    # ä¼°ç®— 61 å±‚çš„æ€»å»¶è¿Ÿï¼ˆç®€åŒ–ï¼‰
    # å®é™…ä¸Šå‰3å±‚æ˜¯ Denseï¼Œå58å±‚æ˜¯ MoEï¼Œè¿™é‡Œç®€åŒ–ä¸ºå…¨éƒ¨ MoE
    total_layers = 61
    tier6_estimated_latency = layer_latency * total_layers
    tier6_estimated_tps = 1000 / tier6_estimated_latency * 1536  # batch_size

    print(f"  ä¼°ç®— 61 å±‚å»¶è¿Ÿ: {tier6_estimated_latency:.2f}ms")
    print(f"  ä¼°ç®—ååé‡: {tier6_estimated_tps:.2f} tokens/s")

    # å¯¹æ¯”
    print("\n" + "-"*80)
    print("å¯¹æ¯”ç»“æœ")
    print("-"*80)

    latency_diff = abs(ds_latency - tier6_estimated_latency) / ds_latency * 100
    tps_diff = abs(ds_tps - tier6_estimated_tps) / ds_tps * 100

    print(f"\nå»¶è¿Ÿå¯¹æ¯”:")
    print(f"  DS_TPU:  {ds_latency:.2f}ms")
    print(f"  Tier6:   {tier6_estimated_latency:.2f}ms")
    print(f"  å·®å¼‚:    {latency_diff:.1f}%")

    print(f"\nååé‡å¯¹æ¯”:")
    print(f"  DS_TPU:  {ds_tps:.2f} tokens/s")
    print(f"  Tier6:   {tier6_estimated_tps:.2f} tokens/s")
    print(f"  å·®å¼‚:    {tps_diff:.1f}%")

    if latency_diff < 20 and tps_diff < 20:
        print("\nâœ… æ¨¡å‹çº§åˆ«è¯„ä¼°ç»“æœåŸºæœ¬ä¸€è‡´ï¼ˆå·®å¼‚ <20%ï¼‰")
        return True
    else:
        print("\nâš ï¸  æ¨¡å‹çº§åˆ«è¯„ä¼°ç»“æœå­˜åœ¨å·®å¼‚ï¼ˆå·®å¼‚ >=20%ï¼‰")
        return False


def main():
    print("="*80)
    print("ğŸ”¬ Tier6+Model vs DS_TPU ç»“æœå¯¹æ¯”")
    print("="*80)

    success1 = test_single_operator_comparison()
    success2 = test_model_level_comparison()

    print("\n" + "="*80)
    if success1 and success2:
        print("âœ… æ‰€æœ‰å¯¹æ¯”æµ‹è¯•é€šè¿‡ï¼ä¸¤ä¸ªç³»ç»Ÿçš„è¯„ä¼°ç»“æœä¸€è‡´")
    else:
        print("âš ï¸  å¯¹æ¯”æµ‹è¯•å‘ç°å·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ")
    print("="*80)


if __name__ == "__main__":
    main()
