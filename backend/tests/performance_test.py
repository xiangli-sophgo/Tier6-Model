"""
æ€§èƒ½æµ‹è¯•è„šæœ¬

ç”¨äºå¿«é€Ÿæµ‹è¯•æ¨¡æ‹Ÿå™¨çš„æ€§èƒ½ï¼Œæ‰¾å‡ºç“¶é¢ˆ
"""

import time
import logging
from simulator import run_simulation

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# ç®€å•çš„æµ‹è¯•é…ç½®
topology = {
    "pods": [{
        "id": "pod0",
        "racks": [{
            "id": "rack0",
            "boards": [{
                "id": "board0",
                "chips": [
                    {"id": "chip0", "name": "SG2260E", "compute_tflops_fp16": 64, "memory_gb": 64, "memory_bandwidth_gbps": 273}
                ]
            }]
        }]
    }],
    "connections": []
}

model = {
    "model_name": "test",
    "hidden_size": 2048,
    "num_layers": 10,  # åªæµ‹è¯•10å±‚
    "num_attention_heads": 16,
    "intermediate_size": 8192,
}

inference = {
    "batch_size": 1,
    "input_seq_length": 128,
    "output_seq_length": 100,  # ä½†åªä¼šæ¨¡æ‹Ÿ4ä¸ªtoken
}

parallelism = {
    "dp": 1,
    "tp": 1,
    "pp": 1,
    "ep": 1,
}

hardware = {
    "chip": {
        "chip_type": "SG2260E",
        "compute_tflops_fp16": 64,
        "memory_gb": 64,
        "memory_bandwidth_gbps": 273,
    }
}

config = {
    "maxSimulatedTokens": 4,
    "enableDataTransferSimulation": True,
}

print("=" * 80)
print("ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•...")
print("=" * 80)

start = time.time()
result = run_simulation(
    topology_dict=topology,
    model_dict=model,
    inference_dict=inference,
    parallelism_dict=parallelism,
    hardware_dict=hardware,
    config_dict=config,
)
elapsed = time.time() - start

print("=" * 80)
print(f"âœ… æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {elapsed*1000:.2f}ms")
print("=" * 80)
