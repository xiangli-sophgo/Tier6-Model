# Llama2 7B 模型配置

model:
  name: llama2_7b
  type: llm
  family: llama2
  
  # 模型结构
  hidden_size: 4096
  num_layers: 32
  num_heads: 32
  num_kv_heads: 32  # 非 GQA
  intermediate_size: 11008
  vocab_size: 32000
  max_position_embeddings: 4096
  
  # 数据类型
  dtype: bf16
  
  # 激活函数
  hidden_act: silu
  
  # RoPE
  rope_theta: 10000
  
  # RMSNorm
  rms_norm_eps: 1.0e-6

# 派生参数（供参考）
# params_b: 6.74  # 67.4 亿参数
# weight_size_gb: 12.5  # bf16
# kv_cache_per_token_kb: 128  # 32 * 2 * 4096 * 2 / 1024
