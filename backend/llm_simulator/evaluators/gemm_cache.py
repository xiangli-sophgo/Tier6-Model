"""
GEMM æŒä¹…åŒ–ç¼“å­˜ç®¡ç†å™¨

åŠŸèƒ½ï¼š
1. å°† GEMM æœç´¢ç»“æœæŒä¹…åŒ–åˆ°æœ¬åœ° JSON æ–‡ä»¶
2. æ”¯æŒè·¨è¿è¡Œå¤ç”¨ç¼“å­˜
3. æ¶æ„æŒ‡çº¹åŒ¹é…ï¼ˆç¡®ä¿ç¼“å­˜æ­£ç¡®æ€§ï¼‰
4. ç‰ˆæœ¬æ§åˆ¶å’Œå…¼å®¹æ€§æ£€æŸ¥
"""

import json
import hashlib
import logging
from pathlib import Path
from typing import Dict, Optional, TYPE_CHECKING
from datetime import datetime

from .arch_config import AcceleratorMicroArch

if TYPE_CHECKING:
    from .gemm_eval import GEMMResult

logger = logging.getLogger(__name__)

# ç¼“å­˜ç‰ˆæœ¬ï¼ˆè¯„ä¼°é€»è¾‘å˜åŒ–æ—¶é€’å¢ï¼‰
CACHE_VERSION = "1.0.0"
CACHE_FORMAT_VERSION = "2025.01"


class GEMMPersistentCache:
    """GEMM æŒä¹…åŒ–ç¼“å­˜ç®¡ç†å™¨

    è®¾è®¡åŸåˆ™ï¼š
    - ç¼“å­˜é”®å¿…é¡»åŒ…å«ï¼šå½¢çŠ¶ã€æ•°æ®ç±»å‹ã€æ¶æ„æŒ‡çº¹ã€æœç´¢æ¨¡å¼
    - ä½¿ç”¨ JSON æ ¼å¼ï¼ˆæ˜“è¯»ã€è·¨å¹³å°ã€æ— ä¾èµ–ï¼‰
    - æŒ‰æ¶æ„æŒ‡çº¹åˆ†æ–‡ä»¶å­˜å‚¨
    - è‡ªåŠ¨ç‰ˆæœ¬æ£€æŸ¥å’Œå…¼å®¹æ€§éªŒè¯
    """

    def __init__(self, arch: AcceleratorMicroArch):
        """
        åˆå§‹åŒ–æŒä¹…åŒ–ç¼“å­˜

        Args:
            arch: ç¡¬ä»¶å¾®æ¶æ„é…ç½®
        """
        self.arch = arch
        self.arch_fingerprint = self._compute_arch_fingerprint()

        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
        cache_dir = Path(__file__).parent.parent.parent / ".cache" / "gemm"
        cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = cache_dir / f"gemm_cache_{self.arch_fingerprint}.json"

        # å†…å­˜ç¼“å­˜ï¼ˆå¿«é€Ÿè®¿é—®ï¼‰
        self._cache: Dict[str, "GEMMResult"] = {}

        # ç»Ÿè®¡ä¿¡æ¯
        self._cache_hits = 0
        self._cache_misses = 0

        # åŠ è½½æŒä¹…åŒ–ç¼“å­˜
        self._load_from_disk()

    def _compute_arch_fingerprint(self) -> str:
        """
        è®¡ç®—ç¡¬ä»¶æ¶æ„æŒ‡çº¹

        åŒ…å«æ‰€æœ‰å½±å“ GEMM æ€§èƒ½çš„æ¶æ„å‚æ•°

        Returns:
            8 å­—ç¬¦çš„ MD5 hashï¼ˆç”¨äºæ–‡ä»¶åï¼‰
        """
        key_params = {
            "name": self.arch.name,
            "num_cores": self.arch.num_cores,
            "cube_m": self.arch.cube_m,
            "cube_n": self.arch.cube_n,
            "cube_k": self.arch.cube_k,
            "sram_kb": self.arch.sram_size_bytes // 1024,
            "freq_ghz": self.arch.freq_ghz,
            "dram_bw_gbps": self.arch.dram_bandwidth_bytes / 1e9,
            "lane_num": self.arch.lane_num,
            "align_bytes": self.arch.align_bytes,
        }

        # ç”Ÿæˆç¡®å®šæ€§çš„ hash
        key_str = json.dumps(key_params, sort_keys=True)
        return hashlib.md5(key_str.encode()).hexdigest()[:8]

    def _make_cache_key(
        self,
        G: int, M: int, K: int, N: int,
        input_dtype: str, output_dtype: str,
        enable_tile_search: bool,
        enable_partition_search: bool
    ) -> str:
        """
        æ„é€ å®Œæ•´ç¼“å­˜é”®

        åŒ…å«ï¼šå½¢çŠ¶ã€æ•°æ®ç±»å‹ã€æ¶æ„æŒ‡çº¹ã€æœç´¢æ¨¡å¼

        Returns:
            ç¼“å­˜é”®çš„ hash å­—ç¬¦ä¸²
        """
        cache_key_tuple = (
            G, M, K, N,
            input_dtype, output_dtype,
            self.arch_fingerprint,
            enable_tile_search,
            enable_partition_search
        )

        # ç”Ÿæˆ hashï¼ˆç”¨äºå¿«é€Ÿç´¢å¼•å’Œæ–‡ä»¶å­˜å‚¨ï¼‰
        key_str = json.dumps(cache_key_tuple, sort_keys=True)
        return hashlib.md5(key_str.encode()).hexdigest()[:12]

    def get(
        self,
        G: int, M: int, K: int, N: int,
        input_dtype: str, output_dtype: str,
        enable_tile_search: bool,
        enable_partition_search: bool
    ) -> Optional["GEMMResult"]:
        """
        ä»ç¼“å­˜ä¸­è·å– GEMM è¯„ä¼°ç»“æœ

        Args:
            G, M, K, N: GEMM å½¢çŠ¶å‚æ•°
            input_dtype: è¾“å…¥æ•°æ®ç±»å‹
            output_dtype: è¾“å‡ºæ•°æ®ç±»å‹
            enable_tile_search: æ˜¯å¦å¯ç”¨ tile æœç´¢
            enable_partition_search: æ˜¯å¦å¯ç”¨åˆ†åŒºæœç´¢

        Returns:
            ç¼“å­˜çš„è¯„ä¼°ç»“æœï¼Œå¦‚æœæœªå‘½ä¸­åˆ™è¿”å› None
        """
        cache_key = self._make_cache_key(
            G, M, K, N, input_dtype, output_dtype,
            enable_tile_search, enable_partition_search
        )

        result = self._cache.get(cache_key)
        if result is not None:
            self._cache_hits += 1
        else:
            self._cache_misses += 1

        return result

    def put(
        self,
        G: int, M: int, K: int, N: int,
        input_dtype: str, output_dtype: str,
        enable_tile_search: bool,
        enable_partition_search: bool,
        result: "GEMMResult",
        search_time_ms: float
    ):
        """
        ä¿å­˜ GEMM è¯„ä¼°ç»“æœåˆ°ç¼“å­˜

        Args:
            G, M, K, N: GEMM å½¢çŠ¶å‚æ•°
            input_dtype: è¾“å…¥æ•°æ®ç±»å‹
            output_dtype: è¾“å‡ºæ•°æ®ç±»å‹
            enable_tile_search: æ˜¯å¦å¯ç”¨ tile æœç´¢
            enable_partition_search: æ˜¯å¦å¯ç”¨åˆ†åŒºæœç´¢
            result: GEMM è¯„ä¼°ç»“æœ
            search_time_ms: æœç´¢è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
        """
        cache_key = self._make_cache_key(
            G, M, K, N, input_dtype, output_dtype,
            enable_tile_search, enable_partition_search
        )

        # ä¿å­˜åˆ°å†…å­˜
        self._cache[cache_key] = result

        # ä¿å­˜åˆ°ç£ç›˜
        self._save_to_disk(
            cache_key, G, M, K, N, input_dtype, output_dtype,
            enable_tile_search, enable_partition_search,
            result, search_time_ms
        )

    def _load_from_disk(self):
        """ä»ç£ç›˜åŠ è½½ç¼“å­˜"""
        if not self.cache_file.exists():
            logger.info(f"ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°ç¼“å­˜: {self.cache_file}")
            return

        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # ç‰ˆæœ¬æ£€æŸ¥
            if data.get("version") != CACHE_VERSION:
                logger.warning(
                    f"ç¼“å­˜ç‰ˆæœ¬ä¸åŒ¹é… (æ–‡ä»¶: {data.get('version')}, "
                    f"å½“å‰: {CACHE_VERSION})ï¼Œå¿½ç•¥æ—§ç¼“å­˜"
                )
                return

            # æ¶æ„æŒ‡çº¹æ£€æŸ¥
            if data.get("arch_fingerprint") != self.arch_fingerprint:
                logger.warning(
                    f"æ¶æ„æŒ‡çº¹ä¸åŒ¹é… (æ–‡ä»¶: {data.get('arch_fingerprint')}, "
                    f"å½“å‰: {self.arch_fingerprint})ï¼Œå¿½ç•¥ç¼“å­˜"
                )
                return

            # åŠ è½½ç¼“å­˜æ¡ç›®
            loaded_count = 0
            for entry_hash, entry_data in data.get("cache_entries", {}).items():
                try:
                    result = self._reconstruct_result(entry_data["result"])
                    self._cache[entry_hash] = result
                    loaded_count += 1
                except Exception as e:
                    logger.warning(f"åŠ è½½ç¼“å­˜æ¡ç›®å¤±è´¥ {entry_hash}: {e}")

            logger.info(f"âœ… æˆåŠŸåŠ è½½ {loaded_count} æ¡ GEMM ç¼“å­˜è®°å½• (æ¶æ„: {self.arch.name})")

        except Exception as e:
            logger.error(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ç©ºç¼“å­˜")

    def _save_to_disk(
        self,
        cache_key: str,
        G: int, M: int, K: int, N: int,
        input_dtype: str, output_dtype: str,
        enable_tile_search: bool,
        enable_partition_search: bool,
        result: "GEMMResult",
        search_time_ms: float
    ):
        """ä¿å­˜å•æ¡è®°å½•åˆ°ç£ç›˜ï¼ˆå¢é‡æ›´æ–°ï¼‰"""
        try:
            # è¯»å–ç°æœ‰æ•°æ®
            if self.cache_file.exists():
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            else:
                data = self._create_empty_cache_file()

            # æ·»åŠ æ–°æ¡ç›®
            data["cache_entries"][cache_key] = {
                "shape": {"G": G, "M": M, "K": K, "N": N},
                "dtypes": {"input": input_dtype, "output": output_dtype},
                "search_mode": {
                    "tile_search": enable_tile_search,
                    "partition_search": enable_partition_search
                },
                "result": {
                    "latency_us": result.latency_us,
                    "compute_time_us": result.compute_time_us,
                    "memory_time_us": result.memory_time_us,
                    "flops": result.flops,
                    "dram_traffic_bytes": result.dram_traffic_bytes,
                    "arch_utilization": result.arch_utilization,
                    "effective_utilization": result.effective_utilization,
                    "best_tile": list(result.best_tile),
                    "best_loop_order": result.best_loop_order,
                    "best_partition": list(result.best_partition)
                },
                "metadata": {
                    "timestamp": datetime.now().isoformat(),
                    "search_time_ms": search_time_ms
                }
            }

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            data["statistics"]["total_entries"] = len(data["cache_entries"])
            data["statistics"]["last_updated"] = datetime.now().isoformat()
            data["statistics"]["total_search_time_hours"] = (
                data["statistics"].get("total_search_time_hours", 0) +
                search_time_ms / 1000 / 3600
            )

            # åŸå­å†™å…¥ï¼ˆå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†æ›¿æ¢ï¼‰
            tmp_file = self.cache_file.with_suffix('.tmp')
            with open(tmp_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            tmp_file.replace(self.cache_file)

        except Exception as e:
            logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def _create_empty_cache_file(self) -> dict:
        """åˆ›å»ºç©ºç¼“å­˜æ–‡ä»¶ç»“æ„"""
        return {
            "version": CACHE_VERSION,
            "cache_format_version": CACHE_FORMAT_VERSION,
            "arch_fingerprint": self.arch_fingerprint,
            "architecture": {
                "name": self.arch.name,
                "num_cores": self.arch.num_cores,
                "sram_kb": self.arch.sram_size_bytes // 1024,
                "cube_m": self.arch.cube_m,
                "cube_n": self.arch.cube_n,
                "cube_k": self.arch.cube_k,
                "freq_ghz": self.arch.freq_ghz,
                "dram_bw_gbps": self.arch.dram_bandwidth_bytes / 1e9,
            },
            "cache_entries": {},
            "statistics": {
                "total_entries": 0,
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat(),
                "total_search_time_hours": 0.0,
                "cache_hits": 0,
                "cache_misses": 0
            }
        }

    def _reconstruct_result(self, result_data: dict) -> "GEMMResult":
        """ä» JSON æ•°æ®é‡å»º GEMMResult å¯¹è±¡"""
        from .gemm_eval import GEMMResult

        return GEMMResult(
            latency_us=result_data["latency_us"],
            compute_time_us=result_data["compute_time_us"],
            memory_time_us=result_data["memory_time_us"],
            flops=result_data["flops"],
            dram_traffic_bytes=result_data["dram_traffic_bytes"],
            arch_utilization=result_data["arch_utilization"],
            effective_utilization=result_data["effective_utilization"],
            best_tile=tuple(result_data["best_tile"]),
            best_loop_order=result_data["best_loop_order"],
            best_partition=tuple(result_data["best_partition"])
        )

    def print_cache_stats(self):
        """æ‰“å°ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_queries = self._cache_hits + self._cache_misses
        hit_rate = self._cache_hits / total_queries if total_queries > 0 else 0

        print(f"\nğŸ“Š GEMM æŒä¹…åŒ–ç¼“å­˜ç»Ÿè®¡:")
        print(f"  ç¼“å­˜æ–‡ä»¶: {self.cache_file}")
        print(f"  æ¶æ„æŒ‡çº¹: {self.arch_fingerprint} ({self.arch.name})")
        print(f"  æ€»æ¡ç›®æ•°: {len(self._cache)}")
        print(f"  ç¼“å­˜å‘½ä¸­: {self._cache_hits}")
        print(f"  ç¼“å­˜æœªå‘½ä¸­: {self._cache_misses}")
        print(f"  å‘½ä¸­ç‡: {hit_rate*100:.1f}%")
