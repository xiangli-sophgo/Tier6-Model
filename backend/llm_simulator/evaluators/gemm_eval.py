"""
GEMM ç²¾ç¡®è¯„ä¼°å™¨

ç§»æ¤è‡ª DS_TPU_1209/gemm.pyï¼Œæ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¤šæ ¸åˆ†å—ç­–ç•¥æœç´¢ (æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œ)
2. Tile å¤§å°æœç´¢ï¼ˆå— SRAM çº¦æŸï¼‰
3. å¾ªç¯é¡ºåºä¼˜åŒ–
4. æ¶æ„åˆ©ç”¨ç‡è®¡ç®—
5. è®¡ç®—-æ¬è¿é‡å æ¨¡å‹
"""

import math
import os
from dataclasses import dataclass
from types import SimpleNamespace
from typing import List, Tuple, Dict, Optional
from multiprocessing import Pool, cpu_count

from .arch_config import AcceleratorMicroArch
from .utils import ceil_div, align_up
from .gemm_cache import GEMMPersistentCache

# æ˜¯å¦å¯ç”¨å¤šè¿›ç¨‹æœç´¢ (å¯é€šè¿‡ç¯å¢ƒå˜é‡ç¦ç”¨)
ENABLE_MULTIPROCESS = os.environ.get('GEMM_DISABLE_MULTIPROCESS', '0') != '1'

# æ•°æ®ç±»å‹å­—èŠ‚æ•°
DTYPE_BYTES = {
    'fp32': 4,
    'fp16': 2,
    'bf16': 2,
    'fp8': 1,
    'int8': 1,
}

# DS_TPU å¯¹é½: é»˜è®¤ä½¿ç”¨ FP8 è¾“å…¥ç²¾åº¦ (W8A8 é‡åŒ–æ¨¡å¼)
# è¿™æ˜¯ DeepSeek V3 çš„é»˜è®¤ç²¾åº¦é…ç½®
DEFAULT_INPUT_DTYPE = 'fp8'   # è¾“å…¥/æƒé‡ä½¿ç”¨ FP8
DEFAULT_OUTPUT_DTYPE = 'bf16'  # è¾“å‡ºä½¿ç”¨ BF16


@dataclass
class GEMMResult:
    """GEMM è¯„ä¼°ç»“æœ"""
    latency_us: float
    """æ€»å»¶è¿Ÿ (å¾®ç§’)"""

    compute_time_us: float
    """è®¡ç®—æ—¶é—´ (å¾®ç§’)"""

    memory_time_us: float
    """è®¿å­˜æ—¶é—´ (å¾®ç§’)"""

    flops: int
    """æµ®ç‚¹è¿ç®—æ•°"""

    dram_traffic_bytes: int
    """DRAM æµé‡ (å­—èŠ‚)"""

    arch_utilization: float
    """æ¶æ„åˆ©ç”¨ç‡ (0-1)ï¼Œè€ƒè™‘å¯¹é½æŸå¤±"""

    effective_utilization: float
    """æœ‰æ•ˆåˆ©ç”¨ç‡ (0-1)ï¼Œè€ƒè™‘è®¿å­˜ç“¶é¢ˆ"""

    best_tile: Tuple[int, int, int]
    """æœ€ä½³ Tile å¤§å° (m_t, n_t, k_t)"""

    best_loop_order: str
    """æœ€ä½³å¾ªç¯é¡ºåº ('mnk', 'nkm', 'mkn')"""

    best_partition: Tuple[int, int, int, int]
    """æœ€ä½³å¤šæ ¸åˆ†å— (P_G, P_M, P_N, P_K)"""


class GEMMEvaluator:
    """GEMM ç²¾ç¡®è¯„ä¼°å™¨"""

    def __init__(self, arch: AcceleratorMicroArch, enable_partition_search: bool = True, enable_tile_search: bool = True, max_gemm_processes: Optional[int] = None):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨

        Args:
            arch: ç¡¬ä»¶å¾®æ¶æ„é…ç½®
            enable_partition_search: æ˜¯å¦å¯ç”¨åˆ†åŒºæœç´¢ï¼ˆFalseæ—¶ä½¿ç”¨å›ºå®šåˆ†åŒºï¼Œé€Ÿåº¦æå‡100å€ï¼‰
            enable_tile_search: æ˜¯å¦å¯ç”¨ tile æœç´¢ï¼ˆFalseæ—¶ä½¿ç”¨å›ºå®š tileï¼‰
            max_gemm_processes: GEMM å¹¶è¡Œæœç´¢çš„æœ€å¤§è¿›ç¨‹æ•°ï¼ˆNone æ—¶è‡ªåŠ¨è®¾ç½®ä¸º cpu_count() // 2ï¼‰
        """
        self.arch = arch
        self.enable_partition_search = enable_partition_search
        self.enable_tile_search = enable_tile_search
        self.max_gemm_processes = max_gemm_processes
        self._valid_partitions = self._compute_valid_partitions()

        # æŒä¹…åŒ–ç¼“å­˜ç®¡ç†å™¨ï¼ˆè‡ªåŠ¨åŠ è½½ç£ç›˜ç¼“å­˜ï¼‰
        self.persistent_cache = GEMMPersistentCache(arch)

        # ğŸ“Š ç¼“å­˜ç»Ÿè®¡
        self._cache_hits = 0
        self._cache_misses = 0
        self._total_search_time_ms = 0.0

    def _compute_valid_partitions(self) -> List[Tuple[int, int, int, int]]:
        """
        æšä¸¾æ‰€æœ‰åˆæ³•çš„å¤šæ ¸åˆ†å—æ–¹æ¡ˆ

        çº¦æŸ: P_G Ã— P_M Ã— P_N Ã— P_K = num_cores

        å½“ enable_partition_search=False æ—¶ï¼Œåªè¿”å›å›ºå®šä¼˜åŒ–åˆ†åŒºï¼ˆé€Ÿåº¦æå‡100å€ï¼‰
        """
        cores = self.arch.num_cores

        # å¿«é€Ÿæ¨¡å¼ï¼šä½¿ç”¨å›ºå®šçš„ä¼˜åŒ–åˆ†åŒº
        if not self.enable_partition_search:
            # å¯¹äº64æ ¸èŠ¯ç‰‡ï¼š(1, 8, 8, 1) æ˜¯å¸¸ç”¨çš„ä¼˜åŒ–åˆ†åŒº
            # å¯¹äºå…¶ä»–æ ¸æ•°ï¼šå°è¯•å¹³è¡¡ M å’Œ N ç»´åº¦
            import math
            sqrt_cores = int(math.sqrt(cores))
            # ä¼˜å…ˆåˆ†è§£ä¸º (1, sqrt, sqrt, 1) å½¢å¼
            if sqrt_cores * sqrt_cores == cores:
                return [(1, sqrt_cores, sqrt_cores, 1)]
            else:
                # å¦åˆ™ä½¿ç”¨ (1, cores, 1, 1) ä¿å®ˆæ–¹æ¡ˆ
                return [(1, cores, 1, 1)]

        # å®Œæ•´æœç´¢æ¨¡å¼ï¼šæšä¸¾æ‰€æœ‰å¯èƒ½çš„åˆ†åŒº
        partitions = []
        for p_g in range(1, cores + 1):
            if cores % p_g != 0:
                continue
            rem_m = cores // p_g

            for p_m in range(1, rem_m + 1):
                if rem_m % p_m != 0:
                    continue
                rem_n = rem_m // p_m

                for p_n in range(1, rem_n + 1):
                    if rem_n % p_n != 0:
                        continue
                    p_k = rem_n // p_n
                    partitions.append((p_g, p_m, p_n, p_k))

        return partitions

    def _find_legal_tiles(
        self,
        m_blk: int,
        n_blk: int,
        k_blk: int,
        input_dtype_bytes: int,
        output_dtype_bytes: int,
    ) -> List[Tuple[int, int, int]]:
        """
        æœç´¢æ‰€æœ‰èƒ½æ”¾è¿› SRAM çš„ Tile å¤§å°

        SRAM å¸ƒå±€:
        - A tile: [m_t, k_t] Ã— input_dtype_bytes
        - B tile: [k_t, n_t] Ã— input_dtype_bytes
        - C tile: [m_t, n_t] Ã— output_dtype_bytes
        """
        if m_blk <= 0 or n_blk <= 0 or k_blk <= 0:
            return [(0, 0, 0)]

        tiles = []
        cube_m = self.arch.cube_m
        cube_n = self.arch.cube_n
        cube_k = self.arch.cube_k
        sram_limit = self.arch.effective_sram_bytes
        lane_num = self.arch.lane_num
        align_bytes = self.arch.align_bytes

        # å¯¹é½å‡½æ•°
        def align_row(r: int) -> int:
            return align_up(r, lane_num)

        def align_col(c: int, elem_bytes: int) -> int:
            return align_up(c * elem_bytes, align_bytes)

        # ä»å¤§åˆ°å°æœç´¢ Tile (è¶Šå¤§è¶Šå¥½ï¼Œæ•°æ®å¤ç”¨è¶Šå¤š)
        m_start = align_up(m_blk, cube_m)
        n_start = align_up(n_blk, cube_n)

        for m_t in range(m_start, 0, -cube_m):
            # å…è®¸ m_t è‡³å°‘è¾¾åˆ° cube_mï¼ˆæœ€å°å¯¹é½å•å…ƒï¼‰
            if m_t > max(m_blk * 2, cube_m):
                continue
            align_row_m = align_row(m_t)

            for n_t in range(n_start, 0, -cube_n):
                # å…è®¸ n_t è‡³å°‘è¾¾åˆ° cube_n
                if n_t > max(n_blk * 2, cube_n):
                    continue
                align_col_n = align_col(n_t, output_dtype_bytes)
                align_row_n = align_row(n_t)  # ç”¨äº B tile è®¡ç®—

                # C tile å¿…é¡»æ”¾å¾—ä¸‹: C[m_t, n_t]
                # è¡Œæ•°å¯¹é½åˆ° lane_numï¼Œåˆ—å­—èŠ‚æ•°å¯¹é½åˆ° align_bytes
                c_tile_bytes = align_row_m * align_col_n
                avail = sram_limit - c_tile_bytes

                if avail <= 0:
                    continue

                # è®¡ç®—æœ€å¤§ k_t
                # A tile: [m_t, k_t]ï¼Œæ¯å¢åŠ  1 ä¸ª k éœ€è¦ align_row_m * input_dtype_bytes
                # B tile: [k_t, n_t]ï¼Œæ¯å¢åŠ  1 ä¸ª k éœ€è¦ align_row_n * input_dtype_bytes
                bytes_per_k = (align_row_m + align_row_n) * input_dtype_bytes
                if bytes_per_k <= 0:
                    max_k = k_blk
                else:
                    max_k = int(avail / bytes_per_k)

                if max_k <= 0:
                    continue

                # å¯¹é½åˆ° cube_k
                k_t = min(k_blk, max_k)
                if k_t >= cube_k:
                    k_t = (k_t // cube_k) * cube_k

                if k_t <= 0:
                    continue

                # Pareto æœ€ä¼˜æ£€æŸ¥ (å»é™¤è¢«æ”¯é…çš„ tile)
                is_dominated = any(
                    m0 >= m_t and n0 >= n_t and k0 >= k_t
                    for m0, n0, k0 in tiles
                )
                if not is_dominated:
                    tiles.append((m_t, n_t, k_t))

        # å¦‚æœæ²¡æ‰¾åˆ°åˆæ³• tileï¼Œä½¿ç”¨æœ€å°çš„ cube å¤§å°
        if not tiles:
            tiles.append((cube_m, cube_n, min(k_blk, cube_k)))

        return tiles

    def _calc_dram_traffic(
        self,
        loop_order: str,
        m_blk: int,
        n_blk: int,
        k_blk: int,
        m_t: int,
        n_t: int,
        k_t: int,
        input_dtype_bytes: int,
        output_dtype_bytes: int,
    ) -> int:
        """
        è®¡ç®— DRAM æµé‡ (å­—èŠ‚)

        ä¸åŒå¾ªç¯é¡ºåºçš„æµé‡å·®å¼‚:
        - mnk: K åœ¨æœ€å†…å±‚ï¼ŒA/B å„é‡å¤åŠ è½½ tile_num_n/tile_num_m æ¬¡
        - nkm: M åœ¨æœ€å†…å±‚ï¼ŒB åªåŠ è½½ä¸€æ¬¡ï¼Œä½† C éœ€è¦å¤šæ¬¡ç´¯åŠ 
        - mkn: N åœ¨æœ€å†…å±‚ï¼ŒA åªåŠ è½½ä¸€æ¬¡ï¼Œä½† C éœ€è¦å¤šæ¬¡ç´¯åŠ 
        """
        if m_blk <= 0 or n_blk <= 0 or k_blk <= 0:
            return 0

        if m_t <= 0 or n_t <= 0 or k_t <= 0:
            return 0

        tile_num_m = ceil_div(m_blk, m_t)
        tile_num_n = ceil_div(n_blk, n_t)
        tile_num_k = ceil_div(k_blk, k_t)

        a_size = m_blk * k_blk * input_dtype_bytes
        b_size = n_blk * k_blk * input_dtype_bytes
        c_size = m_blk * n_blk * output_dtype_bytes

        if loop_order == 'mnk':
            # A é‡å¤ tile_num_n æ¬¡, B é‡å¤ tile_num_m æ¬¡
            return a_size * tile_num_n + b_size * tile_num_m + c_size

        elif loop_order == 'nkm':
            # B åªåŠ è½½ä¸€æ¬¡, A é‡å¤ tile_num_n æ¬¡
            # C éœ€è¦ tile_num_k - 1 æ¬¡ç´¯åŠ  (è¯»+å†™ FP32)
            fp32_bytes = 4
            partial_sum_traffic = m_blk * n_blk * fp32_bytes * 2 * max(0, tile_num_k - 1)
            return b_size + a_size * tile_num_n + partial_sum_traffic + c_size

        else:  # mkn
            # A åªåŠ è½½ä¸€æ¬¡, B é‡å¤ tile_num_m æ¬¡
            fp32_bytes = 4
            partial_sum_traffic = m_blk * n_blk * fp32_bytes * 2 * max(0, tile_num_k - 1)
            return a_size + b_size * tile_num_m + partial_sum_traffic + c_size

    def _calc_arch_utilization(
        self,
        g_blk: int,
        m_blk: int,
        n_blk: int,
        k_blk: int,
    ) -> Tuple[float, float]:
        """
        è®¡ç®—æ¶æ„åˆ©ç”¨ç‡å’Œè®¡ç®—æ—¶é—´

        æ¶æ„åˆ©ç”¨ç‡ = å®é™… MACs / å¯¹é½åç†è®º MACs

        Returns:
            (arch_utilization, compute_time_us)
        """
        if m_blk <= 0 or n_blk <= 0 or k_blk <= 0:
            return 0.0, 0.0

        # å®é™… MAC æ•°
        real_macs = m_blk * n_blk * k_blk

        # å¯¹é½åçš„ç†è®º MAC æ•°
        theo_macs = (
            align_up(m_blk, self.arch.cube_m) *
            align_up(k_blk, self.arch.cube_k) *
            align_up(n_blk, self.arch.cube_n)
        )

        arch_util = real_macs / theo_macs if theo_macs > 0 else 0.0

        # è®¡ç®—æ—¶é—´ (å¾®ç§’)
        # t_us = theo_macs Ã— g_blk / macs_per_cycle / (freq_ghz * 1e3)
        # freq_ghz * 1e3 = GHz * 1000 = cycles/Î¼s
        macs_per_cycle = self.arch.macs_per_cycle
        freq = self.arch.freq_ghz
        if macs_per_cycle <= 0 or freq <= 0:
            t_us = 0.0
        else:
            t_us = theo_macs * g_blk / macs_per_cycle / freq / 1e3

        return arch_util, t_us

    def _evaluate_partition(
        self,
        p_g: int,
        p_m: int,
        p_n: int,
        p_k: int,
        G: int,
        M: int,
        N: int,
        K: int,
        input_dtype_bytes: int,
        output_dtype_bytes: int,
    ) -> Tuple[float, GEMMResult]:
        """
        è¯„ä¼°å•ä¸ªåˆ†å—æ–¹æ¡ˆ

        Returns:
            (total_time_us, GEMMResult)
        """
        # æ¯æ ¸åˆ†é…çš„ç»´åº¦
        g_nom = ceil_div(G, p_g) if p_g > 0 else G
        m_nom = ceil_div(M, p_m) if p_m > 0 else M
        n_nom = ceil_div(N, p_n) if p_n > 0 else N
        k_nom = ceil_div(K, p_k) if p_k > 0 else K

        # æœç´¢æœ€ä½³ tile å’Œå¾ªç¯é¡ºåº
        tiles = self._find_legal_tiles(m_nom, n_nom, k_nom, input_dtype_bytes, output_dtype_bytes)

        min_traffic = float('inf')
        best_tile = tiles[0] if tiles else (self.arch.cube_m, self.arch.cube_n, self.arch.cube_k)
        best_order = 'mnk'

        for m_t, n_t, k_t in tiles:
            if m_t <= 0:
                continue
            for order in ('mnk', 'nkm', 'mkn'):
                traffic = self._calc_dram_traffic(
                    order, m_nom, n_nom, k_nom, m_t, n_t, k_t,
                    input_dtype_bytes, output_dtype_bytes
                )
                if traffic < min_traffic:
                    min_traffic = traffic
                    best_tile = (m_t, n_t, k_t)
                    best_order = order

        m_t, n_t, k_t = best_tile

        # éå†æ‰€æœ‰æ ¸å¿ƒï¼Œè®¡ç®—æœ€é•¿æ‰§è¡Œæ—¶é—´
        total_flops = 0
        total_traffic = 0
        max_time = 0.0
        best_t_comp = 0.0
        best_t_dma = 0.0

        for i_g in range(p_g):
            g_start = i_g * g_nom
            g_blk = max(min(G - g_start, g_nom), 0)

            for i_m in range(p_m):
                m_start = i_m * m_nom
                m_blk = max(min(M - m_start, m_nom), 0)

                for i_n in range(p_n):
                    n_start = i_n * n_nom
                    n_blk = max(min(N - n_start, n_nom), 0)

                    for i_k in range(p_k):
                        k_start = i_k * k_nom
                        k_blk = max(min(K - k_start, k_nom), 0)

                        if g_blk <= 0 or m_blk <= 0 or n_blk <= 0 or k_blk <= 0:
                            continue

                        # è®¡ç®—å½“å‰æ ¸å¿ƒçš„ FLOPs
                        core_flops = 2 * g_blk * m_blk * n_blk * k_blk

                        # è®¡ç®—æ¶æ„åˆ©ç”¨ç‡å’Œè®¡ç®—æ—¶é—´
                        arch_util, t_comp = self._calc_arch_utilization(g_blk, m_blk, n_blk, k_blk)

                        # è®¡ç®— DRAM æµé‡å’Œè®¿å­˜æ—¶é—´
                        traffic = g_blk * self._calc_dram_traffic(
                            best_order, m_blk, n_blk, k_blk, m_t, n_t, k_t,
                            input_dtype_bytes, output_dtype_bytes
                        )

                        dma_bw = self.arch.dma_bandwidth_per_core
                        t_dma = 1e6 * traffic / dma_bw if dma_bw > 0 else 0.0

                        # è®¡ç®—-æ¬è¿é‡å 
                        overlap = self.arch.compute_dma_overlap_rate
                        t_total = (min(t_comp, t_dma) * (1 - overlap) +
                                   max(t_comp, t_dma))

                        # æ›´æ–°ç»Ÿè®¡
                        if t_total > max_time:
                            max_time = t_total
                            best_t_comp = t_comp
                            best_t_dma = t_dma

                        total_flops += core_flops
                        total_traffic += traffic

        # è®¡ç®—æ€»ä½“åˆ©ç”¨ç‡
        # å…¬å¼: total_flops / (max_time_us * 1e3 * cores * macs_per_cycle * freq * 2)
        # ä¸ DS_TPU å…¬å¼å®Œå…¨ä¸€è‡´
        if max_time > 0:
            overall_util = total_flops / (
                max_time * 1e3 *
                self.arch.num_cores *
                self.arch.macs_per_cycle *
                self.arch.freq_ghz * 2
            )
        else:
            overall_util = 0.0

        # è®¡ç®—æ¶æ„åˆ©ç”¨ç‡ï¼ˆåŸºäºæœ€æ…¢æ ¸å¿ƒï¼‰
        if best_t_comp > 0 and max_time > 0:
            arch_util_avg = best_t_comp / max_time
        else:
            arch_util_avg = 0.0

        result = GEMMResult(
            latency_us=max_time,
            compute_time_us=best_t_comp,
            memory_time_us=best_t_dma,
            flops=total_flops,
            dram_traffic_bytes=int(total_traffic),
            arch_utilization=arch_util_avg,
            effective_utilization=overall_util,
            best_tile=best_tile,
            best_loop_order=best_order,
            best_partition=(p_g, p_m, p_n, p_k),
        )

        return max_time, result

    def evaluate(
        self,
        G: int,
        M: int,
        K: int,
        N: int,
        input_dtype: str = "bf16",
        output_dtype: str = "bf16",
        use_multiprocess: bool = True,
    ) -> GEMMResult:
        """
        è¯„ä¼° GEMM: C[G, M, N] = A[G, M, K] Ã— B[G, K, N]

        Args:
            G: Batch/Group ç»´åº¦ (å¯ä»¥æ˜¯ 1)
            M: è¾“å‡ºè¡Œæ•°
            K: ç´¯åŠ ç»´åº¦
            N: è¾“å‡ºåˆ—æ•°
            input_dtype: è¾“å…¥æ•°æ®ç±»å‹ ('fp8', 'bf16', 'fp16')
            output_dtype: è¾“å‡ºæ•°æ®ç±»å‹ ('bf16', 'fp32')
            use_multiprocess: æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œæœç´¢ (é»˜è®¤ True)

        Returns:
            GEMMResult: åŒ…å«å»¶è¿Ÿã€åˆ©ç”¨ç‡ã€æœ€ä½³é…ç½®ç­‰
        """
        # æ£€æŸ¥æŒä¹…åŒ–ç¼“å­˜
        cached_result = self.persistent_cache.get(
            G, M, K, N, input_dtype, output_dtype,
            self.enable_tile_search, self.enable_partition_search
        )
        if cached_result is not None:
            # ğŸ“Š ç¼“å­˜å‘½ä¸­
            self._cache_hits += 1
            return cached_result

        # ğŸ“Š ç¼“å­˜æœªå‘½ä¸­ï¼Œè®°å½•æœç´¢æ—¶é—´
        import time
        search_start = time.time()

        input_bytes = DTYPE_BYTES.get(input_dtype, 2)
        output_bytes = DTYPE_BYTES.get(output_dtype, 2)

        # ç‰¹æ®Šæƒ…å†µå¤„ç†
        if G <= 0 or M <= 0 or K <= 0 or N <= 0:
            result = GEMMResult(
                latency_us=0.0,
                compute_time_us=0.0,
                memory_time_us=0.0,
                flops=0,
                dram_traffic_bytes=0,
                arch_utilization=0.0,
                effective_utilization=0.0,
                best_tile=(0, 0, 0),
                best_loop_order='mnk',
                best_partition=(1, 1, 1, 1),
            )
            # ä¿å­˜åˆ°æŒä¹…åŒ–ç¼“å­˜
            self.persistent_cache.put(
                G, M, K, N, input_dtype, output_dtype,
                self.enable_tile_search, self.enable_partition_search,
                result, search_time_ms=0.0
            )
            return result

        best_time = float('inf')
        best_result_dict = None

        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
        use_mp = use_multiprocess and ENABLE_MULTIPROCESS and len(self._valid_partitions) > 1

        if use_mp:
            # å¤šè¿›ç¨‹å¹¶è¡Œæœç´¢
            best_result_dict = self._evaluate_parallel(G, M, N, K, input_bytes, output_bytes)
        else:
            # ä¸²è¡Œæœç´¢
            for partition in self._valid_partitions:
                p_g, p_m, p_n, p_k = partition

                time_us, result = self._evaluate_partition(
                    p_g, p_m, p_n, p_k,
                    G, M, N, K,
                    input_bytes, output_bytes,
                )

                if time_us < best_time and time_us > 0:
                    best_time = time_us
                    best_result_dict = {
                        'latency_us': result.latency_us,
                        'compute_time_us': result.compute_time_us,
                        'memory_time_us': result.memory_time_us,
                        'flops': result.flops,
                        'dram_traffic_bytes': result.dram_traffic_bytes,
                        'arch_utilization': result.arch_utilization,
                        'effective_utilization': result.effective_utilization,
                        'best_tile': result.best_tile,
                        'best_loop_order': result.best_loop_order,
                        'best_partition': result.best_partition,
                    }

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆç»“æœï¼Œè¿”å›ä¸€ä¸ªåŸºäºç®€å•ä¼°ç®—çš„ç»“æœ
        if best_result_dict is None:
            total_flops = 2 * G * M * N * K
            # ç®€å•ä¼°ç®—ï¼šå‡è®¾ 50% åˆ©ç”¨ç‡
            peak_flops = self.arch.flops_per_second
            if peak_flops > 0:
                latency_us = total_flops / (peak_flops * 0.5) * 1e6
            else:
                latency_us = 0.0

            best_result = GEMMResult(
                latency_us=latency_us,
                compute_time_us=latency_us,
                memory_time_us=0.0,
                flops=total_flops,
                dram_traffic_bytes=0,
                arch_utilization=0.5,
                effective_utilization=0.5,
                best_tile=(self.arch.cube_m, self.arch.cube_n, self.arch.cube_k),
                best_loop_order='mnk',
                best_partition=(1, 1, 1, self.arch.num_cores),
            )
        else:
            best_result = GEMMResult(
                latency_us=best_result_dict['latency_us'],
                compute_time_us=best_result_dict['compute_time_us'],
                memory_time_us=best_result_dict['memory_time_us'],
                flops=best_result_dict['flops'],
                dram_traffic_bytes=best_result_dict['dram_traffic_bytes'],
                arch_utilization=best_result_dict['arch_utilization'],
                effective_utilization=best_result_dict['effective_utilization'],
                best_tile=best_result_dict['best_tile'],
                best_loop_order=best_result_dict['best_loop_order'],
                best_partition=best_result_dict['best_partition'],
            )

        # ä¿å­˜åˆ°æŒä¹…åŒ–ç¼“å­˜
        search_time_ms = (time.time() - search_start) * 1000
        self.persistent_cache.put(
            G, M, K, N, input_dtype, output_dtype,
            self.enable_tile_search, self.enable_partition_search,
            best_result, search_time_ms
        )

        # ğŸ“Š è®°å½•ç¼“å­˜æœªå‘½ä¸­å’Œæœç´¢æ—¶é—´
        self._cache_misses += 1
        self._total_search_time_ms += search_time_ms

        import logging
        logger = logging.getLogger(__name__)
        logger.info(f"ğŸ” GEMM æœç´¢è€—æ—¶: {search_time_ms:.2f}ms, å½¢çŠ¶: ({G}, {M}, {K}, {N})")

        return best_result

    def _evaluate_parallel(
        self,
        G: int,
        M: int,
        N: int,
        K: int,
        input_bytes: int,
        output_bytes: int,
    ) -> Optional[dict]:
        """
        ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œè¯„ä¼°æ‰€æœ‰åˆ†å—æ–¹æ¡ˆ

        Returns:
            æœ€ä½³ç»“æœçš„å­—å…¸ï¼Œå¦‚æœæ— æœ‰æ•ˆç»“æœåˆ™è¿”å› None
        """
        # å‡†å¤‡æ¶æ„å‚æ•° (ç”¨äº pickle)
        arch_params = {
            'cube_m': self.arch.cube_m,
            'cube_n': self.arch.cube_n,
            'cube_k': self.arch.cube_k,
            'effective_sram_bytes': self.arch.effective_sram_bytes,
            'lane_num': self.arch.lane_num,
            'align_bytes': self.arch.align_bytes,
            'macs_per_cycle': self.arch.macs_per_cycle,
            'freq_ghz': self.arch.freq_ghz,
            'dma_bandwidth_per_core': self.arch.dma_bandwidth_per_core,
            'compute_dma_overlap_rate': self.arch.compute_dma_overlap_rate,
            'num_cores': self.arch.num_cores,
        }

        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = [
            (p_g, p_m, p_n, p_k, G, M, N, K, input_bytes, output_bytes, arch_params)
            for p_g, p_m, p_n, p_k in self._valid_partitions
        ]

        # ä½¿ç”¨å¤šè¿›ç¨‹æ± ï¼ˆé™åˆ¶åˆ°æŒ‡å®šæ•°é‡æˆ– CPU æ ¸å¿ƒæ•°çš„ä¸€åŠï¼Œé¿å…ç³»ç»Ÿè¿‡è½½ï¼‰
        if self.max_gemm_processes is not None:
            max_workers = max(1, self.max_gemm_processes)
        else:
            max_workers = max(1, cpu_count() // 2)
        num_processes = min(len(tasks), max_workers)

        try:
            with Pool(processes=num_processes) as pool:
                results = pool.map(_evaluate_partition_worker, tasks)
        except Exception:
            # å¦‚æœå¤šè¿›ç¨‹å¤±è´¥ï¼Œå›é€€åˆ°ä¸²è¡Œ
            results = [_evaluate_partition_worker(task) for task in tasks]

        # æ‰¾æœ€ä¼˜ç»“æœ
        best_time = float('inf')
        best_result_dict = None

        for time_us, result_dict in results:
            if time_us < best_time and time_us > 0:
                best_time = time_us
                best_result_dict = result_dict

        return best_result_dict

    def clear_cache(self):
        """æ¸…ç©ºå†…å­˜ç¼“å­˜ï¼ˆä¸å½±å“ç£ç›˜ç¼“å­˜ï¼‰"""
        self.persistent_cache._cache.clear()
        self._cache_hits = 0
        self._cache_misses = 0
        self._total_search_time_ms = 0.0

    def get_cache_stats(self) -> dict:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            åŒ…å«ç¼“å­˜å‘½ä¸­ç‡ã€æœç´¢æ—¶é—´ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        total_requests = self._cache_hits + self._cache_misses
        hit_rate = (self._cache_hits / total_requests * 100) if total_requests > 0 else 0.0

        return {
            "total_requests": total_requests,
            "cache_hits": self._cache_hits,
            "cache_misses": self._cache_misses,
            "hit_rate_percent": hit_rate,
            "cached_configs": len(self.persistent_cache._cache),
            "total_search_time_ms": self._total_search_time_ms,
            "avg_search_time_ms": (self._total_search_time_ms / self._cache_misses) if self._cache_misses > 0 else 0.0,
            "cache_file": str(self.persistent_cache.cache_file),
        }

    def print_cache_stats(self):
        """æ‰“å°ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_cache_stats()
        import logging
        logger = logging.getLogger(__name__)

        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info("ğŸ“Š GEMM æŒä¹…åŒ–ç¼“å­˜ç»Ÿè®¡")
        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info(f"   ç¼“å­˜æ–‡ä»¶: {stats['cache_file']}")
        logger.info(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
        logger.info(f"   ç¼“å­˜å‘½ä¸­: {stats['cache_hits']} ({stats['hit_rate_percent']:.1f}%)")
        logger.info(f"   ç¼“å­˜æœªå‘½ä¸­: {stats['cache_misses']}")
        logger.info(f"   å·²ç¼“å­˜é…ç½®: {stats['cached_configs']}")
        logger.info(f"   æ€»æœç´¢æ—¶é—´: {stats['total_search_time_ms']:.2f}ms")
        if stats['cache_misses'] > 0:
            logger.info(f"   å¹³å‡æœç´¢æ—¶é—´: {stats['avg_search_time_ms']:.2f}ms/æ¬¡")
        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")


# ==================== å¤šè¿›ç¨‹è¾…åŠ©å‡½æ•° ====================

def _evaluate_partition_worker(args):
    """
    å¤šè¿›ç¨‹ worker å‡½æ•°

    å¿…é¡»æ˜¯æ¨¡å—çº§å‡½æ•°æ‰èƒ½è¢« pickle
    """
    (p_g, p_m, p_n, p_k, G, M, N, K, input_bytes, output_bytes, arch_params) = args

    # é‡å»ºç®€åŒ–çš„æ¶æ„å¯¹è±¡ç”¨äºè®¡ç®—
    arch = SimpleNamespace(**arch_params)

    # åˆ›å»ºä¸´æ—¶è¯„ä¼°å™¨
    evaluator = _PartitionEvaluator(arch)
    return evaluator.evaluate_partition(
        p_g, p_m, p_n, p_k,
        G, M, N, K,
        input_bytes, output_bytes,
    )


class _PartitionEvaluator:
    """
    è½»é‡çº§åˆ†åŒºè¯„ä¼°å™¨ï¼Œç”¨äºå¤šè¿›ç¨‹
    """

    def __init__(self, arch):
        self.arch = arch

    def _find_legal_tiles(
        self,
        m_blk: int,
        n_blk: int,
        k_blk: int,
        input_dtype_bytes: int,
        output_dtype_bytes: int,
    ) -> List[Tuple[int, int, int]]:
        """æœç´¢æ‰€æœ‰èƒ½æ”¾è¿› SRAM çš„ Tile å¤§å°"""
        if m_blk <= 0 or n_blk <= 0 or k_blk <= 0:
            return [(0, 0, 0)]

        tiles = []
        cube_m = self.arch.cube_m
        cube_n = self.arch.cube_n
        cube_k = self.arch.cube_k
        sram_limit = self.arch.effective_sram_bytes
        lane_num = self.arch.lane_num
        align_bytes = self.arch.align_bytes

        def align_row(r: int) -> int:
            return align_up(r, lane_num)

        def align_col(c: int, elem_bytes: int) -> int:
            return align_up(c * elem_bytes, align_bytes)

        m_start = align_up(m_blk, cube_m)
        n_start = align_up(n_blk, cube_n)

        for m_t in range(m_start, 0, -cube_m):
            # å…è®¸ m_t è‡³å°‘è¾¾åˆ° cube_mï¼ˆæœ€å°å¯¹é½å•å…ƒï¼‰
            if m_t > max(m_blk * 2, cube_m):
                continue
            align_row_m = align_row(m_t)

            for n_t in range(n_start, 0, -cube_n):
                # å…è®¸ n_t è‡³å°‘è¾¾åˆ° cube_n
                if n_t > max(n_blk * 2, cube_n):
                    continue
                align_col_n = align_col(n_t, output_dtype_bytes)
                align_row_n = align_row(n_t)

                # C tile: [m_t, n_t]ï¼Œè¡Œæ•°å¯¹é½åˆ° lane_num
                c_tile_bytes = align_row_m * align_col_n
                avail = sram_limit - c_tile_bytes

                if avail <= 0:
                    continue

                # A tile: [m_t, k_t]ï¼ŒB tile: [k_t, n_t]
                # bytes_per_k = A æ¯å¢åŠ  1 ä¸ª k çš„å­—èŠ‚æ•° + B æ¯å¢åŠ  1 ä¸ª k çš„å­—èŠ‚æ•°
                bytes_per_k = (align_row_m + align_row_n) * input_dtype_bytes
                if bytes_per_k <= 0:
                    max_k = k_blk
                else:
                    max_k = int(avail / bytes_per_k)

                if max_k <= 0:
                    continue

                k_t = min(k_blk, max_k)
                if k_t >= cube_k:
                    k_t = (k_t // cube_k) * cube_k

                if k_t <= 0:
                    continue

                is_dominated = any(
                    m0 >= m_t and n0 >= n_t and k0 >= k_t
                    for m0, n0, k0 in tiles
                )
                if not is_dominated:
                    tiles.append((m_t, n_t, k_t))

        if not tiles:
            tiles.append((cube_m, cube_n, min(k_blk, cube_k)))

        return tiles

    def _calc_dram_traffic(
        self,
        loop_order: str,
        m_blk: int,
        n_blk: int,
        k_blk: int,
        m_t: int,
        n_t: int,
        k_t: int,
        input_dtype_bytes: int,
        output_dtype_bytes: int,
    ) -> int:
        """è®¡ç®— DRAM æµé‡"""
        if m_blk <= 0 or n_blk <= 0 or k_blk <= 0:
            return 0
        if m_t <= 0 or n_t <= 0 or k_t <= 0:
            return 0

        tile_num_m = ceil_div(m_blk, m_t)
        tile_num_n = ceil_div(n_blk, n_t)
        tile_num_k = ceil_div(k_blk, k_t)

        a_size = m_blk * k_blk * input_dtype_bytes
        b_size = n_blk * k_blk * input_dtype_bytes
        c_size = m_blk * n_blk * output_dtype_bytes

        if loop_order == 'mnk':
            return a_size * tile_num_n + b_size * tile_num_m + c_size
        elif loop_order == 'nkm':
            fp32_bytes = 4
            partial_sum_traffic = m_blk * n_blk * fp32_bytes * 2 * max(0, tile_num_k - 1)
            return b_size + a_size * tile_num_n + partial_sum_traffic + c_size
        else:  # mkn
            fp32_bytes = 4
            partial_sum_traffic = m_blk * n_blk * fp32_bytes * 2 * max(0, tile_num_k - 1)
            return a_size + b_size * tile_num_m + partial_sum_traffic + c_size

    def _calc_arch_utilization(
        self,
        g_blk: int,
        m_blk: int,
        n_blk: int,
        k_blk: int,
    ) -> Tuple[float, float]:
        """è®¡ç®—æ¶æ„åˆ©ç”¨ç‡å’Œè®¡ç®—æ—¶é—´"""
        if m_blk <= 0 or n_blk <= 0 or k_blk <= 0:
            return 0.0, 0.0

        real_macs = m_blk * n_blk * k_blk
        theo_macs = (
            align_up(m_blk, self.arch.cube_m) *
            align_up(k_blk, self.arch.cube_k) *
            align_up(n_blk, self.arch.cube_n)
        )

        arch_util = real_macs / theo_macs if theo_macs > 0 else 0.0

        macs_per_cycle = self.arch.macs_per_cycle
        freq = self.arch.freq_ghz
        if macs_per_cycle <= 0 or freq <= 0:
            t_us = 0.0
        else:
            t_us = theo_macs * g_blk / macs_per_cycle / freq / 1e3

        return arch_util, t_us

    def evaluate_partition(
        self,
        p_g: int,
        p_m: int,
        p_n: int,
        p_k: int,
        G: int,
        M: int,
        N: int,
        K: int,
        input_dtype_bytes: int,
        output_dtype_bytes: int,
    ) -> Tuple[float, dict]:
        """è¯„ä¼°å•ä¸ªåˆ†å—æ–¹æ¡ˆï¼Œè¿”å› (time, result_dict)"""
        g_nom = ceil_div(G, p_g) if p_g > 0 else G
        m_nom = ceil_div(M, p_m) if p_m > 0 else M
        n_nom = ceil_div(N, p_n) if p_n > 0 else N
        k_nom = ceil_div(K, p_k) if p_k > 0 else K

        tiles = self._find_legal_tiles(m_nom, n_nom, k_nom, input_dtype_bytes, output_dtype_bytes)

        min_traffic = float('inf')
        best_tile = tiles[0] if tiles else (self.arch.cube_m, self.arch.cube_n, self.arch.cube_k)
        best_order = 'mnk'

        for m_t, n_t, k_t in tiles:
            if m_t <= 0:
                continue
            for order in ('mnk', 'nkm', 'mkn'):
                traffic = self._calc_dram_traffic(
                    order, m_nom, n_nom, k_nom, m_t, n_t, k_t,
                    input_dtype_bytes, output_dtype_bytes
                )
                if traffic < min_traffic:
                    min_traffic = traffic
                    best_tile = (m_t, n_t, k_t)
                    best_order = order

        m_t, n_t, k_t = best_tile

        total_flops = 0
        total_traffic = 0
        max_time = 0.0
        best_t_comp = 0.0
        best_t_dma = 0.0

        for i_g in range(p_g):
            g_start = i_g * g_nom
            g_blk = max(min(G - g_start, g_nom), 0)

            for i_m in range(p_m):
                m_start = i_m * m_nom
                m_blk = max(min(M - m_start, m_nom), 0)

                for i_n in range(p_n):
                    n_start = i_n * n_nom
                    n_blk = max(min(N - n_start, n_nom), 0)

                    for i_k in range(p_k):
                        k_start = i_k * k_nom
                        k_blk = max(min(K - k_start, k_nom), 0)

                        if g_blk <= 0 or m_blk <= 0 or n_blk <= 0 or k_blk <= 0:
                            continue

                        core_flops = 2 * g_blk * m_blk * n_blk * k_blk
                        arch_util, t_comp = self._calc_arch_utilization(g_blk, m_blk, n_blk, k_blk)

                        traffic = g_blk * self._calc_dram_traffic(
                            best_order, m_blk, n_blk, k_blk, m_t, n_t, k_t,
                            input_dtype_bytes, output_dtype_bytes
                        )

                        dma_bw = self.arch.dma_bandwidth_per_core
                        t_dma = 1e6 * traffic / dma_bw if dma_bw > 0 else 0.0

                        overlap = self.arch.compute_dma_overlap_rate
                        t_total = (min(t_comp, t_dma) * (1 - overlap) +
                                   max(t_comp, t_dma))

                        if t_total > max_time:
                            max_time = t_total
                            best_t_comp = t_comp
                            best_t_dma = t_dma

                        total_flops += core_flops
                        total_traffic += traffic

        if max_time > 0:
            overall_util = total_flops / (
                max_time * 1e3 *
                self.arch.num_cores *
                self.arch.macs_per_cycle *
                self.arch.freq_ghz * 2
            )
        else:
            overall_util = 0.0

        if best_t_comp > 0 and max_time > 0:
            arch_util_avg = best_t_comp / max_time
        else:
            arch_util_avg = 0.0

        result_dict = {
            'latency_us': max_time,
            'compute_time_us': best_t_comp,
            'memory_time_us': best_t_dma,
            'flops': total_flops,
            'dram_traffic_bytes': int(total_traffic),
            'arch_utilization': arch_util_avg,
            'effective_utilization': overall_util,
            'best_tile': best_tile,
            'best_loop_order': best_order,
            'best_partition': (p_g, p_m, p_n, p_k),
        }

        return max_time, result_dict


# ==================== ä¾¿æ·æ¥å£ ====================

_evaluator_cache: Dict[int, GEMMEvaluator] = {}


def get_gemm_evaluator(arch: AcceleratorMicroArch) -> GEMMEvaluator:
    """è·å–æˆ–åˆ›å»º GEMM è¯„ä¼°å™¨ (ç¼“å­˜å•ä¾‹)"""
    key = id(arch)
    if key not in _evaluator_cache:
        _evaluator_cache[key] = GEMMEvaluator(arch)
    return _evaluator_cache[key]


def eval_gemm(
    arch: AcceleratorMicroArch,
    G: int,
    M: int,
    K: int,
    N: int,
    input_dtype: str = "bf16",
    output_dtype: str = "bf16",
) -> GEMMResult:
    """
    å¿«é€Ÿè¯„ä¼° GEMM

    Args:
        arch: ç¡¬ä»¶å¾®æ¶æ„é…ç½®
        G, M, K, N: GEMM ç»´åº¦
        input_dtype: è¾“å…¥ç±»å‹
        output_dtype: è¾“å‡ºç±»å‹

    Returns:
        GEMMResult
    """
    evaluator = get_gemm_evaluator(arch)
    return evaluator.evaluate(G, M, K, N, input_dtype, output_dtype)
