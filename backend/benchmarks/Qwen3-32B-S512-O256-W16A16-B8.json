{
  "id": "Qwen3-32B-S512-O256-W16A16-B8",
  "name": "Qwen3-32B-S512-O256-W16A16-B8",
  "model": {
    "model_name": "Qwen3-32B",
    "model_type": "dense",
    "hidden_size": 5120,
    "num_layers": 64,
    "num_attention_heads": 64,
    "num_kv_heads": 8,
    "intermediate_size": 25600,
    "vocab_size": 151936,
    "weight_dtype": "bf16",
    "activation_dtype": "bf16",
    "max_seq_length": 131072,
    "norm_type": "rmsnorm",
    "attention_type": "gqa"
  },
  "inference": {
    "batch_size": 8,
    "input_seq_length": 512,
    "output_seq_length": 256,
    "max_seq_length": 768,
    "num_micro_batches": 4
  }
}
