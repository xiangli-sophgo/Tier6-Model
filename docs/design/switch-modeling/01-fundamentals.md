# 交换机基础架构与微架构

## 一、交换机核心架构

### 1.1 基本组成

现代数据中心交换机由以下核心组件构成:

```
                    +---------------------------+
                    |    调度器 (Scheduler)      |
                    |   iSLIP / PIM 仲裁算法     |
                    +-------------+-------------+
                                  |
+----------+    +-----------------+-----------------+    +----------+
| 入口端口  |--->|       交换结构 (Crossbar)         |--->| 出口端口  |
|          |    |   输入缓冲区 (VOQ)                 |    |          |
| 解析/查表 |    |   输出缓冲区 (Output Buffer)       |    | 队列调度  |
+----------+    +-----------------------------------+    +----------+
```

### 1.2 缓冲策略分类

| 策略 | 描述 | 吞吐上限 | 适用场景 |
|------|------|---------|---------|
| **Output Queuing (OQ)** | 仅在出口端缓冲 | 100% | 理论最优，需 N 倍加速比 |
| **Input Queuing (IQ)** | 仅在入口端缓冲 | 58.6% | 简单但有 HOL 阻塞 |
| **VOQ** | 每个输入为每个输出维护独立队列 | ~100% | **数据中心主流** |
| **CIOQ** | 混合输入输出缓冲 | ~100% | 高端交换机 |

### 1.3 Virtual Output Queuing (VOQ) 详解

VOQ 是现代高性能交换机的核心架构:

```
输入端口 0                              输出端口
  +-- VOQ(0,0) -----------------------> 端口 0
  +-- VOQ(0,1) -----------------------> 端口 1
  +-- VOQ(0,2) -----------------------> 端口 2
  +-- VOQ(0,N) -----------------------> 端口 N

输入端口 1
  +-- VOQ(1,0) -----------------------> 端口 0
  +-- VOQ(1,1) -----------------------> 端口 1
  ...
```

**关键特性**:
- 消除 Head-of-Line (HOL) 阻塞
- 需要 N x N 个虚拟队列 (N 为端口数)
- 依赖高效调度算法 (iSLIP, PIM 等)
- 内存开销: O(N^2) 个队列

---

## 二、转发模式

### 2.1 Store-and-Forward (存储转发)

完整接收帧后进行 CRC 校验，确认无误后转发。

```
入口:   [====== 接收完整帧 ======]
                                 |
处理:                            [CRC校验][MAC查表][QoS分类]
                                                   |
出口:                                              [====== 发送帧 ======]

延迟 = T_serialization_in + T_processing + T_queueing
     = (frame_size * 8 / BW) + T_crc + T_lookup + T_queue
```

- 优点: 完整错误检测，支持速率转换和 QoS
- 缺点: 延迟与帧大小成正比

### 2.2 Cut-Through (直通转发)

只读取帧头部的目标 MAC 地址 (前 14 字节)，立即开始转发。

```
入口:   [目标MAC][源MAC][=========== 剩余数据 ===========][FCS]
             |
处理:        [CAM表查找]
                  |
出口:             [目标MAC][源MAC][=========== 剩余数据 ===========][FCS]

延迟 = T_header + T_lookup ~= 100-400 ns (与帧大小无关)
```

- 优点: 超低延迟，流水线处理
- 缺点: 无错误过滤，入口/出口速率必须匹配
- **数据中心主流方案**

### 2.3 模式对比

| 模式 | 转发前读取 | 典型延迟 (100GbE) | 错误检测 | 适用场景 |
|------|-----------|-------------------|----------|----------|
| **Cut-Through** | 14 字节 | ~300-500ns | 无 | 数据中心核心 |
| **Fragment-Free** | 64 字节 | ~800ns | Runt 帧 | 折中方案 |
| **Store-and-Forward** | 完整帧 | 数 us | 完整 CRC | 需要 QoS/速率转换 |
| **Adaptive** | 动态 | 动态 | 动态 | 错误率波动的网络 |

**实际影响**: Cut-Through 在出口端口拥塞时会退化为 Store-and-Forward。

---

## 三、iSLIP 调度算法

iSLIP (Iterative Round-Robin Matching) 是数据中心交换机的核心调度算法。

### 3.1 算法流程

每个时间槽执行 1-4 次迭代:

```
Iteration k (k = 1, 2, ..., max_iterations):

Step 1: Request (请求)
  每个输入端口 i 向所有非空 VOQ 的目标输出端口 j 发送请求

Step 2: Grant (授权)
  每个输出端口 j 使用 Round-Robin 仲裁器选择一个请求
  指针 grant_ptr[j] 指向优先级最高的输入
  *仅当授权被接受时*才更新指针

Step 3: Accept (接受)
  每个输入端口 i 使用 Round-Robin 仲裁器选择一个授权
  接受后 accept_ptr[i] 移动到 (j+1) mod N
```

### 3.2 指针去同步化

iSLIP 的关键创新: **Grant 指针仅在授权被接受时更新**。未被接受的授权不更新指针。这使得各输出端口的仲裁器指针逐渐去同步化，大幅减少碰撞。

### 3.3 吞吐量特性

| 迭代次数 | 吞吐量 | 延迟 | 推荐场景 |
|---------|--------|------|---------|
| 1 次 | ~63% | 最低 | 低延迟优先 |
| 2 次 | ~99% | 适中 | **推荐** |
| 4 次 | ~99.9% | 较高 | 高吞吐优先 |

---

## 四、共享缓冲池管理

### 4.1 架构

```
              +-------------------------+
              |   Shared Memory Pool    |
              |      (64 MB SRAM)       |
              +-------------------------+
                   |    |    |    |
            +------+----+----+----+------+
            |  Dynamic Allocation Logic  |
            +------+----+----+----+------+
                   |    |    |    |
                 Port1 Port2 ... PortN
```

### 4.2 动态阈值 (DT) 算法

```
每个 VOQ 的最大可用缓冲:

  Static_Reserved = 保底缓冲 (如 128 KB/VOQ)
  Shared_Available = Total_Buffer - Current_Usage
  Dynamic_Quota = alpha * Shared_Available
  Max_Allowed = Static_Reserved + Dynamic_Quota

alpha 参数:
  alpha = 1.0: 平均分配
  alpha > 1.0: 激进 (允许占用更多共享缓冲，吸收突发)
  alpha < 1.0: 保守 (防止单个队列占用过多)
```

### 4.3 缓冲溢出处理

| 策略 | 行为 | 适用场景 |
|------|------|---------|
| **Tail Drop** | VOQ 满时丢弃新包 | 默认策略 |
| **ECN Marking** | 超过阈值时标记 ECN，不丢弃 | 无损网络 (RDMA) |
| **WRED** | 按概率提前丢弃，避免同步丢包 | TCP 网络 |

---

## 五、流量控制

### 5.1 Credit-Based Flow Control

端口间的精细流控机制，数据中心高速互联常用:

```
发送端:
  credits[neighbor] = neighbor_buffer_depth  (初始化)

  每发送 1 个 packet:
    credits[neighbor] -= 1

  每收到 1 个 credit 反馈:
    credits[neighbor] += 1

  发送条件:
    can_send = (credits[neighbor] > 0) and (packet in VOQ)

接收端:
  每接收 1 个 packet 并从 buffer 移除:
    send_credit_to_sender()
```

优势: 细粒度控制 (逐包)，零丢包保证。

### 5.2 PFC (Priority Flow Control)

支持每优先级独立暂停:

```
接收端:
  优先级 3 的队列将满
       |
  发送 PFC 帧: PAUSE 优先级 3
       |
发送端:
  只暂停优先级 3 的流量
  其他优先级 (0,1,2,4,5,6,7) 继续发送
```

详见 [02-ai-networking.md](./02-ai-networking.md) 中的 PFC 详解。

---

## 六、QoS 机制

### 6.1 流量分类

基于 802.1p 优先级 (VLAN 标签中的 PCP 字段):

| PCP 值 | 优先级名称 | 典型应用 |
|--------|-----------|---------|
| 7 | 网络控制 (NC) | 路由协议, LACP |
| 5 | 语音 (VO) | VoIP |
| 4 | 视频 (VI) | 视频会议 |
| 3 | 关键应用 (CA) | **RDMA 数据流量** |
| 0 | 背景 (BK) | 批量下载 |

### 6.2 队列调度算法

| 算法 | 特点 | 适用场景 |
|------|------|---------|
| **FIFO** | 先进先出，无优先级 | 尽力而为流量 |
| **Strict Priority** | 高优先级绝对优先 | 延迟敏感流量 (可能饥饿) |
| **WRR** | 按权重比例分配带宽 | 避免饥饿 |
| **WFQ** | 基于包大小和权重的公平性 | 考虑帧大小差异 |
| **DWRR** | 解决 WRR 的帧大小问题 | **数据中心常用** |

---

## 七、延迟模型

### 7.1 完整延迟组成

```
T_total = T_propagation + T_serialization + T_processing + T_queueing

其中:
  T_propagation   = distance / c        # 传播延迟 (光纤中 ~5us/km)
  T_serialization = packet_size / BW    # 串行化延迟
  T_processing    = T_lookup + T_switch # 处理延迟 (查表+交换)
  T_queueing      = f(rho, buffer, traffic) # 排队延迟 (负载相关)
```

### 7.2 典型值参考

| 参数 | 10GbE | 100GbE | 400GbE |
|------|-------|--------|--------|
| 串行化延迟 (64B) | 51.2ns | 5.12ns | 1.28ns |
| 串行化延迟 (1KB) | 819ns | 81.9ns | 20.5ns |
| 串行化延迟 (9KB MTU) | 7.37us | 737ns | 184ns |
| 典型处理延迟 | 300ns-1us | 300ns-1us | 300ns-1us |

### 7.3 排队论近似

**M/M/1 模型** (通用分析):

```
利用率:        rho = lambda / mu  (必须 < 1)
平均队列长度:   L = rho / (1 - rho)
平均等待时间:   W = 1 / (mu - lambda)
```

**M/D/1 模型** (固定包长):

```
平均等待时间:   W = 1/mu * (2-rho) / (2*(1-rho))
相比 M/M/1:    W_MD1 / W_MM1 ~= 0.5 (rho->1 时)
```

**M/M/1/K 模型** (有限缓冲，用于 VOQ 建模):

```
丢包概率:   P_loss = (1-rho) * rho^K / (1-rho^(K+1))
```

**注意**: 排队论模型仅用于快速估算。Cycle 级建模将使用状态机模拟替代这些近似公式。
